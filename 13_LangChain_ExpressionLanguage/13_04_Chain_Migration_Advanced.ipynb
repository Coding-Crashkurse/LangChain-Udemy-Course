{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"the dog loves to eat pizza\", metadata={\"source\": \"animal.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"the cat loves to eat lasagna\", metadata={\"source\": \"animal.txt\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "llm = ChatOpenAI()\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"What exactly?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "qa_template = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer\n",
    "the question. If you don't know the answer, say that you\n",
    "don't know. Use three sentences maximum and keep the\n",
    "answer concise.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Other context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_template(qa_template)\n",
    "\n",
    "convo_qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever,\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\n",
    "        \"prompt\": qa_prompt,\n",
    "    },\n",
    ")\n",
    "\n",
    "convo_qa_chain(\n",
    "    {\n",
    "        \"question\": \"What kind of food does the cat like?\",\n",
    "        \"chat_history\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "rephrase_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "REPHRASE_TEMPLATE = PromptTemplate.from_template(rephrase_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "rephrase_chain = REPHRASE_TEMPLATE | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rephrase_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"No, really?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"What does the dog like to eat?\"),\n",
    "            AIMessage(content=\"Thuna!\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | ANSWER_PROMPT\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = rephrase_chain | retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"No, really?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"What does the dog like to eat?\"),\n",
    "            AIMessage(content=\"Thuna!\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with returning documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = {\"docs\": retriever, \"question\": RunnablePassthrough()}\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: \"\\n\".join(doc.page_content for doc in x[\"docs\"]),\n",
    "    \"question\": lambda x: x[\"question\"],\n",
    "}\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | ChatOpenAI() | StrOutputParser(),\n",
    "    \"docs\": lambda x: x[\"docs\"],\n",
    "}\n",
    "\n",
    "final_chain = rephrase_chain | retrieved_documents | answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"No, really?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"What does the dog like to eat?\"),\n",
    "            AIMessage(content=\"Thuna!\"),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"docs\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
